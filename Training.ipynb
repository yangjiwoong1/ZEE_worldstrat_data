{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a super-resolution model\n",
    "\n",
    "The dataset comes with several pretrained super-resolution models we used as a benchmark:\n",
    "\n",
    "- HighResNet\n",
    "- SRCNN Multi-Frame\n",
    "- SRCNN Single-Image\n",
    "\n",
    "We trained the models on a [p3.2xlarge](https://aws.amazon.com/ec2/instance-types/p3/) instance,\n",
    "and the training usually takes about 45 min - 1.5 hr on a single GPU instance, using 8 low-resolution revisits and the entire dataset.\n",
    "\n",
    "The splits we used are available in the `stratified_train_val_test_split.csv` file.  \n",
    "These splits are stratified to ensure equal representation of all LCCS/IPCC/SMOD classes within each split.  \n",
    "To run on a smaller subset, you can manually specify the number of AOIs to be used in each split using the `--train_split`, `--val_split`, `--test_split` arguments.\n",
    "\n",
    "To train the network, or reproduce this benchmark, you can run the following commands:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from src.train import *\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_train_command = [\n",
    "    # Batch size, gpus, limits\n",
    "    \"python\",\n",
    "    \"--batch_size\", \"16\",\n",
    "    \"--gpus\", \"-1\", # if you want to use cpu, comment out this line\n",
    "    \"--max_steps\", \"50000\",\n",
    "    \"--precision\", \"16\",\n",
    "    \"--num_workers\", \"8\", # set your own number of workers(cpu cores)\n",
    "\n",
    "    # Model/Hyperparameters\n",
    "    \"--model\", \"srcnn\",\n",
    "    \"--w_mse\", \"0.3\",\n",
    "    \"--w_mae\", \"0.4\",\n",
    "    \"--w_ssim\", \"0.3\",\n",
    "    \"--hidden_channels\", \"128\",\n",
    "    \"--shift_px\", \"2\",\n",
    "    \"--shift_mode\", \"lanczos\",\n",
    "    \"--shift_step\", \"0.5\",\n",
    "    \"--residual_layers\", \"1\",\n",
    "    \"--learning_rate\", \"1e-4\",\n",
    "    \n",
    "    # Data\n",
    "    \"--dataset\", \"JIF\",\n",
    "    \"--root\", \"dataset\", # dataset directory name\n",
    "    \"--revisits\", \"1\", # single frame SR\n",
    "    \"--input_size\", \"160\", \"160\",\n",
    "    \"--output_size\", \"500\", \"500\",\n",
    "    \"--chip_size\", \"80\", \"80\",\n",
    "    \"--chip_stride\", \"80\", \"80\",\n",
    "    \"--lr_bands_to_use\", \"true_color\",\n",
    "    \"--use_single_frame_sr\", \"True\",\n",
    "    \"--normalize_lr\", \"True\",\n",
    "    \"--randomly_rotate_and_flip_images\", \"True\",\n",
    "    \"--shuffle\", \"True\",\n",
    "    \"--subset_train\", \"0.2\",\n",
    "    #\"--radiometry_depth\", \"12\",\n",
    "\n",
    "    # Training, validation, test splits\n",
    "    \"--list_of_aois\", \"dataset/train_val_test.csv\",\n",
    "    \n",
    "    # WandB 기본적으로 비활성화\n",
    "    # 필요한 경우 아래 라인의 주석을 해제하여 WandB 활성화\n",
    "    #\"--use_wandb\"\n",
    "]\n",
    "\n",
    "def run_training_command(training_command, running_on_windows=True):\n",
    "    sys.argv = training_command\n",
    "    if running_on_windows:\n",
    "        sys.argv += [\"--num_workers\", \"0\"]\n",
    "    cli_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: Keep in mind the training was done on an instance with 1xV100 and 64 GB of RAM.  \n",
    "The batch size might be too large for your local computer.  \n",
    "\n",
    "If CUDA runs out of memory, consider decreasing it above in the `default_training_command`.  \n",
    "You can also decrease the number of revisits to any number from 1 to 8.\n",
    "\n",
    "If CUDA runs out of shared memory, you can increase it on Linux by running:  \n",
    "`sudo mount -o remount,size={YOUR_RAM_SIZE, e.g. 64G} /dev/shm`\n",
    "\n",
    "If running on Windows, set the `running_on_windows` flag in the `run_train_command` function to True."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_training_command(default_train_command, running_on_windows=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducing the benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_random_seeds = [431608443, 122938034, 315114726]\n",
    "benchmark_data_seed = 386564310\n",
    "\n",
    "# HighResNet triple replicates\n",
    "highresnet_replicates = [\n",
    "    default_train_command \n",
    "    + [\"--data_split_seed\", str(benchmark_data_seed)]\n",
    "    + [\"--seed\", str(seed)] \n",
    "    for seed in benchmark_random_seeds\n",
    "]\n",
    "\n",
    "# SRCNN MultiFrame triple replicates\n",
    "# Change model to SRCNN\n",
    "\n",
    "default_train_command[10] = 'srcnn'\n",
    "srcnn_multiframe_replicates = [\n",
    "    default_train_command \n",
    "    + [\"--data_split_seed\", str(benchmark_data_seed)]\n",
    "    + [\"--seed\", str(seed)] \n",
    "    for seed in benchmark_random_seeds\n",
    "]\n",
    "\n",
    "# SRCNN Single Image triple replicates\n",
    "# Change number of revisits to 1\n",
    "default_train_command[34] = '1'\n",
    "srcnn_single_image_replicates = [\n",
    "    default_train_command \n",
    "    + [\"--data_split_seed\", str(benchmark_data_seed)]\n",
    "    + [\"--seed\", str(seed)] \n",
    "    for seed in benchmark_random_seeds\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for replicates in [highresnet_replicates, srcnn_multiframe_replicates, srcnn_single_image_replicates]:\n",
    "    for replicate_training_command in replicates:\n",
    "        run_training_command(replicate_training_command, running_on_windows=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "worldstrat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
